{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-04-24T11:59:43.219524Z","iopub.status.busy":"2023-04-24T11:59:43.219087Z","iopub.status.idle":"2023-04-24T11:59:43.251030Z","shell.execute_reply":"2023-04-24T11:59:43.249440Z","shell.execute_reply.started":"2023-04-24T11:59:43.219489Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchinfo import summary\n","\n","class BasicBlock(nn.Module):\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes)\n","            )\n","\n","        # SE layers\n","        self.fc1 = nn.Conv2d(planes, planes//16, kernel_size=1)  # Use nn.Conv2d instead of nn.Linear\n","        self.fc2 = nn.Conv2d(planes//16, planes, kernel_size=1)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","\n","        # Squeeze\n","        w = F.avg_pool2d(out, out.size(2))\n","        w = F.relu(self.fc1(w))\n","        w = F.sigmoid(self.fc2(w))\n","        # Excitation\n","        out = out * w  # New broadcasting feature from v0.2!\n","\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class PreActBlock(nn.Module):\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(PreActBlock, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","\n","        if stride != 1 or in_planes != planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False)\n","            )\n","\n","        # SE layers\n","        self.fc1 = nn.Conv2d(planes, planes//16, kernel_size=1)\n","        self.fc2 = nn.Conv2d(planes//16, planes, kernel_size=1)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(x))\n","        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n","        out = self.conv1(out)\n","        out = self.conv2(F.relu(self.bn2(out)))\n","\n","        # Squeeze\n","        w = F.avg_pool2d(out, out.size(2))\n","        w = F.relu(self.fc1(w))\n","        w = F.sigmoid(self.fc2(w))\n","        # Excitation\n","        out = out * w\n","\n","        out += shortcut\n","        return out\n","\n","\n","class SENet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(SENet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block,  64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out=self.linear(out)\n","        return out\n","\n","\n","\n","def SENet18():\n","    return SENet(PreActBlock, [2,2,2,2])\n","def SENet34():\n","    return SENet(PreActBlock, [3, 4, 6, 3])\n","def SENet50():\n","    return SENet(PreActBlock, [3, 4, 6, 3])\n","def SENet101():\n","    return SENet(PreActBlock, [3, 4, 23, 3])\n","def SENet152():\n","    return SENet(PreActBlock, [3, 8, 36, 3])"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-24T11:59:43.253485Z","iopub.status.busy":"2023-04-24T11:59:43.253141Z","iopub.status.idle":"2023-04-24T11:59:44.349412Z","shell.execute_reply":"2023-04-24T11:59:44.348057Z","shell.execute_reply.started":"2023-04-24T11:59:43.253454Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","SENet                                    [32, 10]                  --\n","├─Conv2d: 1-1                            [32, 64, 28, 28]          1,728\n","├─BatchNorm2d: 1-2                       [32, 64, 28, 28]          128\n","├─Sequential: 1-3                        [32, 64, 28, 28]          --\n","│    └─PreActBlock: 2-1                  [32, 64, 28, 28]          --\n","│    │    └─BatchNorm2d: 3-1             [32, 64, 28, 28]          128\n","│    │    └─Conv2d: 3-2                  [32, 64, 28, 28]          36,864\n","│    │    └─BatchNorm2d: 3-3             [32, 64, 28, 28]          128\n","│    │    └─Conv2d: 3-4                  [32, 64, 28, 28]          36,864\n","│    │    └─Conv2d: 3-5                  [32, 4, 1, 1]             260\n","│    │    └─Conv2d: 3-6                  [32, 64, 1, 1]            320\n","│    └─PreActBlock: 2-2                  [32, 64, 28, 28]          --\n","│    │    └─BatchNorm2d: 3-7             [32, 64, 28, 28]          128\n","│    │    └─Conv2d: 3-8                  [32, 64, 28, 28]          36,864\n","│    │    └─BatchNorm2d: 3-9             [32, 64, 28, 28]          128\n","│    │    └─Conv2d: 3-10                 [32, 64, 28, 28]          36,864\n","│    │    └─Conv2d: 3-11                 [32, 4, 1, 1]             260\n","│    │    └─Conv2d: 3-12                 [32, 64, 1, 1]            320\n","│    └─PreActBlock: 2-3                  [32, 64, 28, 28]          --\n","│    │    └─BatchNorm2d: 3-13            [32, 64, 28, 28]          128\n","│    │    └─Conv2d: 3-14                 [32, 64, 28, 28]          36,864\n","│    │    └─BatchNorm2d: 3-15            [32, 64, 28, 28]          128\n","│    │    └─Conv2d: 3-16                 [32, 64, 28, 28]          36,864\n","│    │    └─Conv2d: 3-17                 [32, 4, 1, 1]             260\n","│    │    └─Conv2d: 3-18                 [32, 64, 1, 1]            320\n","├─Sequential: 1-4                        [32, 128, 14, 14]         --\n","│    └─PreActBlock: 2-4                  [32, 128, 14, 14]         --\n","│    │    └─BatchNorm2d: 3-19            [32, 64, 28, 28]          128\n","│    │    └─Sequential: 3-20             [32, 128, 14, 14]         8,192\n","│    │    └─Conv2d: 3-21                 [32, 128, 14, 14]         73,728\n","│    │    └─BatchNorm2d: 3-22            [32, 128, 14, 14]         256\n","│    │    └─Conv2d: 3-23                 [32, 128, 14, 14]         147,456\n","│    │    └─Conv2d: 3-24                 [32, 8, 1, 1]             1,032\n","│    │    └─Conv2d: 3-25                 [32, 128, 1, 1]           1,152\n","│    └─PreActBlock: 2-5                  [32, 128, 14, 14]         --\n","│    │    └─BatchNorm2d: 3-26            [32, 128, 14, 14]         256\n","│    │    └─Conv2d: 3-27                 [32, 128, 14, 14]         147,456\n","│    │    └─BatchNorm2d: 3-28            [32, 128, 14, 14]         256\n","│    │    └─Conv2d: 3-29                 [32, 128, 14, 14]         147,456\n","│    │    └─Conv2d: 3-30                 [32, 8, 1, 1]             1,032\n","│    │    └─Conv2d: 3-31                 [32, 128, 1, 1]           1,152\n","│    └─PreActBlock: 2-6                  [32, 128, 14, 14]         --\n","│    │    └─BatchNorm2d: 3-32            [32, 128, 14, 14]         256\n","│    │    └─Conv2d: 3-33                 [32, 128, 14, 14]         147,456\n","│    │    └─BatchNorm2d: 3-34            [32, 128, 14, 14]         256\n","│    │    └─Conv2d: 3-35                 [32, 128, 14, 14]         147,456\n","│    │    └─Conv2d: 3-36                 [32, 8, 1, 1]             1,032\n","│    │    └─Conv2d: 3-37                 [32, 128, 1, 1]           1,152\n","│    └─PreActBlock: 2-7                  [32, 128, 14, 14]         --\n","│    │    └─BatchNorm2d: 3-38            [32, 128, 14, 14]         256\n","│    │    └─Conv2d: 3-39                 [32, 128, 14, 14]         147,456\n","│    │    └─BatchNorm2d: 3-40            [32, 128, 14, 14]         256\n","│    │    └─Conv2d: 3-41                 [32, 128, 14, 14]         147,456\n","│    │    └─Conv2d: 3-42                 [32, 8, 1, 1]             1,032\n","│    │    └─Conv2d: 3-43                 [32, 128, 1, 1]           1,152\n","├─Sequential: 1-5                        [32, 256, 7, 7]           --\n","│    └─PreActBlock: 2-8                  [32, 256, 7, 7]           --\n","│    │    └─BatchNorm2d: 3-44            [32, 128, 14, 14]         256\n","│    │    └─Sequential: 3-45             [32, 256, 7, 7]           32,768\n","│    │    └─Conv2d: 3-46                 [32, 256, 7, 7]           294,912\n","│    │    └─BatchNorm2d: 3-47            [32, 256, 7, 7]           512\n","│    │    └─Conv2d: 3-48                 [32, 256, 7, 7]           589,824\n","│    │    └─Conv2d: 3-49                 [32, 16, 1, 1]            4,112\n","│    │    └─Conv2d: 3-50                 [32, 256, 1, 1]           4,352\n","│    └─PreActBlock: 2-9                  [32, 256, 7, 7]           --\n","│    │    └─BatchNorm2d: 3-51            [32, 256, 7, 7]           512\n","│    │    └─Conv2d: 3-52                 [32, 256, 7, 7]           589,824\n","│    │    └─BatchNorm2d: 3-53            [32, 256, 7, 7]           512\n","│    │    └─Conv2d: 3-54                 [32, 256, 7, 7]           589,824\n","│    │    └─Conv2d: 3-55                 [32, 16, 1, 1]            4,112\n","│    │    └─Conv2d: 3-56                 [32, 256, 1, 1]           4,352\n","│    └─PreActBlock: 2-10                 [32, 256, 7, 7]           --\n","│    │    └─BatchNorm2d: 3-57            [32, 256, 7, 7]           512\n","│    │    └─Conv2d: 3-58                 [32, 256, 7, 7]           589,824\n","│    │    └─BatchNorm2d: 3-59            [32, 256, 7, 7]           512\n","│    │    └─Conv2d: 3-60                 [32, 256, 7, 7]           589,824\n","│    │    └─Conv2d: 3-61                 [32, 16, 1, 1]            4,112\n","│    │    └─Conv2d: 3-62                 [32, 256, 1, 1]           4,352\n","│    └─PreActBlock: 2-11                 [32, 256, 7, 7]           --\n","│    │    └─BatchNorm2d: 3-63            [32, 256, 7, 7]           512\n","│    │    └─Conv2d: 3-64                 [32, 256, 7, 7]           589,824\n","│    │    └─BatchNorm2d: 3-65            [32, 256, 7, 7]           512\n","│    │    └─Conv2d: 3-66                 [32, 256, 7, 7]           589,824\n","│    │    └─Conv2d: 3-67                 [32, 16, 1, 1]            4,112\n","│    │    └─Conv2d: 3-68                 [32, 256, 1, 1]           4,352\n","│    └─PreActBlock: 2-12                 [32, 256, 7, 7]           --\n","│    │    └─BatchNorm2d: 3-69            [32, 256, 7, 7]           512\n","│    │    └─Conv2d: 3-70                 [32, 256, 7, 7]           589,824\n","│    │    └─BatchNorm2d: 3-71            [32, 256, 7, 7]           512\n","│    │    └─Conv2d: 3-72                 [32, 256, 7, 7]           589,824\n","│    │    └─Conv2d: 3-73                 [32, 16, 1, 1]            4,112\n","│    │    └─Conv2d: 3-74                 [32, 256, 1, 1]           4,352\n","│    └─PreActBlock: 2-13                 [32, 256, 7, 7]           --\n","│    │    └─BatchNorm2d: 3-75            [32, 256, 7, 7]           512\n","│    │    └─Conv2d: 3-76                 [32, 256, 7, 7]           589,824\n","│    │    └─BatchNorm2d: 3-77            [32, 256, 7, 7]           512\n","│    │    └─Conv2d: 3-78                 [32, 256, 7, 7]           589,824\n","│    │    └─Conv2d: 3-79                 [32, 16, 1, 1]            4,112\n","│    │    └─Conv2d: 3-80                 [32, 256, 1, 1]           4,352\n","├─Sequential: 1-6                        [32, 512, 4, 4]           --\n","│    └─PreActBlock: 2-14                 [32, 512, 4, 4]           --\n","│    │    └─BatchNorm2d: 3-81            [32, 256, 7, 7]           512\n","│    │    └─Sequential: 3-82             [32, 512, 4, 4]           131,072\n","│    │    └─Conv2d: 3-83                 [32, 512, 4, 4]           1,179,648\n","│    │    └─BatchNorm2d: 3-84            [32, 512, 4, 4]           1,024\n","│    │    └─Conv2d: 3-85                 [32, 512, 4, 4]           2,359,296\n","│    │    └─Conv2d: 3-86                 [32, 32, 1, 1]            16,416\n","│    │    └─Conv2d: 3-87                 [32, 512, 1, 1]           16,896\n","│    └─PreActBlock: 2-15                 [32, 512, 4, 4]           --\n","│    │    └─BatchNorm2d: 3-88            [32, 512, 4, 4]           1,024\n","│    │    └─Conv2d: 3-89                 [32, 512, 4, 4]           2,359,296\n","│    │    └─BatchNorm2d: 3-90            [32, 512, 4, 4]           1,024\n","│    │    └─Conv2d: 3-91                 [32, 512, 4, 4]           2,359,296\n","│    │    └─Conv2d: 3-92                 [32, 32, 1, 1]            16,416\n","│    │    └─Conv2d: 3-93                 [32, 512, 1, 1]           16,896\n","│    └─PreActBlock: 2-16                 [32, 512, 4, 4]           --\n","│    │    └─BatchNorm2d: 3-94            [32, 512, 4, 4]           1,024\n","│    │    └─Conv2d: 3-95                 [32, 512, 4, 4]           2,359,296\n","│    │    └─BatchNorm2d: 3-96            [32, 512, 4, 4]           1,024\n","│    │    └─Conv2d: 3-97                 [32, 512, 4, 4]           2,359,296\n","│    │    └─Conv2d: 3-98                 [32, 32, 1, 1]            16,416\n","│    │    └─Conv2d: 3-99                 [32, 512, 1, 1]           16,896\n","├─Linear: 1-7                            [32, 10]                  5,130\n","==========================================================================================\n","Total params: 21,440,630\n","Trainable params: 21,440,630\n","Non-trainable params: 0\n","Total mult-adds (G): 29.98\n","==========================================================================================\n","Input size (MB): 0.30\n","Forward/backward pass size (MB): 408.34\n","Params size (MB): 85.76\n","Estimated Total Size (MB): 494.40\n","==========================================================================================\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Anaconda3\\lib\\site-packages\\torchinfo\\torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  action_fn=lambda data: sys.getsizeof(data.storage()),\n","c:\\Anaconda3\\lib\\site-packages\\torch\\storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return super().__sizeof__() + self.nbytes()\n"]}],"source":["def model_test(input_channle=3, image_heigth=224, image_width=224,num_classes=10,batch_size=32):\n","    model = SENet50()\n","    print(summary(model, input_size=(batch_size, 3, 28, 28))) \n","    \n","model_test()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
